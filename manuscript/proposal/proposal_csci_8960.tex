\documentclass{article}

\usepackage[preprint]{neurips_2024}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{array}

\title{Differential Privacy in Image Classification using ResNet-20 and DP-SGD Optimization}

\author{
    Praveen Rangavajhula\\
    Department of Computer Science\\
    University of Georgia\\
    Athens, GA, 30602\\
    \texttt{praveen.rangavajhula@uga.edu} \\
    \And
    Alexander Darwiche\\
    Department of Computer Science\\
    University of Georgia\\
    Athens, GA, 30605 \\
    \texttt{alexander.darwiche@uga.edu} \\
    \And
    Deven Allen\\
    Department of Computer Science\\
    University of Georgia\\
    Athens, GA, 30605 \\
    \texttt{dca09692@uga.edu} \\
}

\begin{document}

    \maketitle

    \begin{abstract}

        This project proposes a differentially private image classification system using ResNet-20 with various
        optimizers, starting with Differentially Private Stochastic Gradient Descent (DP-SGD) as a baseline.
        We aim to make incremental improvements with additional optimization techniques, exploring both non-private
        and DP versions of optimizers, and justifying our choices based on prior work and their potential
        to outperform others.
        The project will focus on achieving competitive accuracy while satisfying privacy guarantees.
        Additionally, we are investigating ways to enhance accuracy by modifying optimizer components,
        such as gradient clipping (potentially using techniques like automatic clipping).

    \end{abstract}


    \section{Introduction}\label{sec:introduction}

    The increase in prevalence of machine learning models, especially in image classification,
    has coincided with concerns over privacy~\cite{papernot2022hyperparametertuningrenyidifferential}.
    Differential privacy (DP) specifically addresses these concerns by ensuring that models do not inadvertently leak sensitive
    information about individual data points.
    In this proposal, we will use the ResNet-20 model, which is well-suited for datasets like CIFAR-10~\cite{Idelbayev_ResNet20},
    and will implement and improve DP-SGD to achieve better privacy guarantees without significantly compromising accuracy.


    \section{Motivation and Problem Statement}\label{sec:motivation-and-problem-statement}
    In many real-world applications, the concerns over privacy leakage can hinder the deployment of machine
    learning models.
    Current state-of-the-art models like ResNet-20 achieve high accuracy but are vulnerable to attacks that could leak
    sensitive information.
    An example of a differentially private optimizer is Differentially Private Stochastic Gradient Descent (DP-SGD), which has been shown
    to effectively reduce privacy leaks, but has challenges in balancing model accuracy and privacy~\cite{Abadi_2016_DeepLearningDifferentialPrivacy}.
    Even with the strong foundation that DP-SGD provides, we believe there is room for improvements that can
    achieve both higher accuracy and stronger privacy guarantees.



    \section{Methodology}\label{sec:methodology}
    \input{methodology}

    \break
    \section{Experimental Setup}\label{sec:experimental-setup}
    \input{experimental-setup}

    \section{Related Work}\label{sec:related-work}
    Several approaches to differentially private deep learning have been explored in the literature.
    Abadi et al. \cite{Abadi_2016_DeepLearningDifferentialPrivacy} introduced DP-SGD, which has become a foundational technique for
    privacy-preserving model training.
    Our focus is on making incremental improvements to this framework by adapting it to DP-RMSprop and DP-Adam.
    Additionally, we aim to incorporate automatic clipping~\cite{bu2023automaticclippingdifferentiallyprivate}.


    \section{Timeline and Milestones}\label{sec:timeline-and-milestones}
    \begin{itemize}
        \item October 4, 2024: Best Accuracy Report 1 Due.
        \item October 18, 2024: Interim Report Due.
        \item November 8, 2024: Best Accuracy Report 2 Due.
        \item November 22, 2024: Final Report Due.
    \end{itemize}

    \section{Best Accuracy Report \#1}\label{sec:best-accuracy-report}
    \input{ba-report}

    \section{Best Accuracy Report \#2}\label{sec:best-accuracy-report}
    \input{ba-report2}

    \bibliographystyle{plain}
    \bibliography{references}

    \section*{GitHub Contributions}
    The code and related materials for this project are available at our GitHub repository:
    \url{https://github.com/CS8960-Privacy-Preserving-Data-Analysis/final-project}.
    Contributions, issues, and discussions are welcome.


\end{document}
