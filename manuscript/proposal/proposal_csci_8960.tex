\documentclass{article}

\usepackage[preprint]{neurips_2024}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}

\title{Differential Privacy in Image Classification using ResNet-20 and DP-SGD Optimization}

\author{
    Praveen Rangavajhula\\
    Department of Computer Science\\
    University of Georgia\\
    Athens, GA, 30602\\
    \texttt{praveen.rangavajhula@uga.edu} \\
    \And
    Alexander Darwiche\\
    Department of Computer Science\\
    University of Georgia\\
    Athens, GA, 30605 \\
    \texttt{alexander.darwiche@uga.edu} \\
    \And
    Deven Allen\\
    Department of Computer Science\\
    University of Georgia\\
    Athens, GA, 30605 \\
    \texttt{dca09692@uga.edu} \\
}

\begin{document}

    \maketitle

    \begin{abstract}

        This project proposes a differentially private image classification system using ResNet-20 with various
        optimizers, starting with Differentially Private Stochastic Gradient Descent (DP-SGD) as a baseline.
        We aim to make incremental improvements with additional optimization techniques, exploring both non-private
        and DP versions of optimizers, and justifying our choices based on prior work and their potential
        to outperform others.
        The project will focus on achieving competitive accuracy while satisfying privacy guarantees.
        Additionally, we are investigating ways to enhance accuracy by modifying optimizer components,
        such as gradient clipping (potentially using techniques like automatic clipping), and exploring
        possible improvements in noise management.

    \end{abstract}


    \section{Introduction}\label{sec:introduction}

    The proliferation of machine learning models, especially in image classification, has raised concerns over privacy.
    Differential privacy (DP) addresses these concerns by ensuring that the model does not inadvertently leak sensitive
    information about individual data points.
    In this proposal, we focus on the ResNet-20 model, which is suited for tasks like CIFAR-10, and aim to implement
    and improve DP-SGD, an existing algorithm for training deep learning models with privacy guarantees.


    \section{Motivation and Problem Statement}\label{sec:motivation-and-problem-statement}
    In many real-world applications, such as healthcare and finance, privacy concerns hinder the deployment of machine
    learning models.
    Current state-of-the-art models like ResNet-20 achieve high accuracy but are vulnerable to attacks
    that could leak sensitive information.
    By incorporating differential privacy through the use of DP-SGD, we aim to
    develop a model that balances both accuracy and privacy.


    \section{Methodology}\label{sec:methodology}

    \subsection{Model Architecture: ResNet-20}\label{subsec:model-architecture:-resnet-20}

    We will utilize the ResNet-20 model~\citet{Idelbayev_ResNet20} for CIFAR-10,
    a standard dataset for image classification tasks.
    Although ResNet-18 is more common, we selected ResNet-20 for its deeper architecture,
    which is suited for our privacy-preserving project.

    If necessary, we may modify the architecture slightly to optimize for DP compatibility.

    \subsection{Non-private Optimizers to Try}\label{subsec:non-private-optimizers-to-try}
    We will first experiment with non-private optimizers to establish baseline performance for ResNet-20 on CIFAR-10.
    The following optimizers will be explored:
    \begin{itemize}
        \item \textbf{SGD:} Standard Stochastic Gradient Descent for baseline comparison.
        \item \textbf{Adam:} Adaptive Moment Estimation for better convergence in non-private settings.
        \item \textbf{RMSprop:} To explore gradient normalization impact in non-private training.
    \end{itemize}

    \subsection{Differentially Private Optimizer: DP-SGD}\label{subsec:differentially-private-optimizer:-dp-sgd}
    We will implement DP-SGD as our privacy-preserving algorithm.
    The key components of DP-SGD are:
    \begin{itemize}
        \item \textbf{Gradient Clipping:} Limits the influence of individual examples during training.
        \item \textbf{Noise Addition:} Adds noise to gradients to ensure privacy (via Opacus or TensorFlow Privacy libraries).
        \item \textbf{Privacy Accounting:} We will use RÃ©nyi Differential Privacy (RDP) for privacy budget tracking.
    \end{itemize}

    \subsection{Incremental Improvements}\label{subsec:incremental-improvements}
    We plan to explore the following enhancements:
    \begin{itemize}
        \item Alternative noise mechanisms and their effect on utility-privacy tradeoffs.
        \item Adaptive gradient clipping methods that dynamically adjust the clipping threshold.
        \item Experimenting with different optimizers (e.g., DP-Adam).
    \end{itemize}

    \subsection{Rationale for Choosing DP-SGD}\label{subsec:rationale-for-choosing-dp-sgd}
    \begin{itemize}
        \item provides well-documented privacy guarantees \citet{Abadi_2016_DeepLearningDifferentialPrivacy}
        while maintaining decent utility for image classification tasks.
        \item The addition of noise and gradient clipping help ensure $(\epsilon, \delta)$-differential privacy,
        making it ideal for sensitive applications.
        \item Previous work shows that DP-SGD, when optimized, can yield near state-of-the-art accuracy
        for differentially private models \citet{De_2022_ScaleDP_ImageClassification}.
    \end{itemize}

    \subsection{Why This Approach Will Outperform Others}\label{subsec:why-this-approach-will-outperform-others}
    \begin{itemize}
        \item Our approach leverages the simplicity of ResNet-20, optimized for smaller datasets like CIFAR-10,
        combined with DP-SGD, a proven differential privacy technique.
        \item By experimenting with different gradient clipping techniques and noise scales,
        we aim to find an optimal trade-off between accuracy and privacy.
        \item We will investigate modifications like adaptive clipping to enhance performance.
    \end{itemize}

    \subsection{Pseudocode for Non-Private SGD}\label{subsec:pseudo-code-for-non-private-sgd}
    Below is a simplified pseudocode for the non-private SGD we plan to privatize:
    \begin{verbatim}
        for each batch (X, y):
            pred = model(X)
            loss = loss_fn(pred, y)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
    \end{verbatim}


    \section{Experimental Setup}\label{sec:experimental-setup}

    \subsection{System Description}\label{subsec:system-description}
    We will use PyTorch~\citep{pytorch_2019} for model implementation and training.
    The DP-SGD~\citep{Abadi_2016_DeepLearningDifferentialPrivacy} implementation will be based on the Opacus library~\citep{opacus}.
    Training will be performed on GPUs available via our departmental server csci-cuda.cs.uga.edu.

    \subsection{Dataset}\label{subsec:dataset}
    We will use the CIFAR-10 dataset~\citep{cifar10_dataset}, consisting of 60,000 32x32 RGB images, which is commonly used for
    image classification tasks.
    The dataset is built-in in PyTorch~\citep{pytorch_2019}, and we will load it using standard libraries.

    \subsection{Metrics}\label{subsec:metrics}
    \begin{itemize}
        \item \textbf{Training Loss/Accuracy:} Standard accuracy and training loss on CIFAR-10~\citep{cifar10_dataset}.
        \item \textbf{Privacy Budget:} We will measure $(\epsilon, \delta)$ using RDP~\citep{Mironov_2017_RenyiDP} to ensure privacy compliance.
        \item \textbf{Efficiency:} Time complexity and memory usage will be tracked.
    \end{itemize}

    \subsection{Baseline Models}\label{subsec:baseline-models}
    We will compare the performance of our modified differentially private models with standard private optimizers,
    including vanilla DP-SGD~\citep{Abadi_2016_DeepLearningDifferentialPrivacy}, DP-Adam,
    and DP-RMSprop~\citep{zhou_2020_private_adaptive_algorithms}.
    Additionally, we will benchmark against AdaClip~\citep{adaClip_2019} to evaluate the effectiveness of our automatic
    clipping and noise mechanism modifications.


    \section{Related Work}\label{sec:related-work}
    Several approaches to differentially private deep learning have been explored in the literature.
    \citet{Abadi_2016_DeepLearningDifferentialPrivacy} introduced DP-SGD, which has become a foundational technique for
    privacy-preserving model training.
    Our focus is on making incremental improvements to this framework by adapting it to DP-Adam and DP-RMSprop.
    Additionally, we aim to incorporate automatic clipping as introduced by \citet{bu2023automaticclippingdifferentiallyprivate}
    and explore modifications to the noise mechanism to enhance performance while maintaining privacy.


    \section{Timeline and Milestones}\label{sec:timeline-and-milestones}
    \begin{itemize}
        \item Week 1--2: Implement ResNet-20 for CIFAR-10.
        \item Week 3--4: Integrate DP-SGD using the Opacus library and test on CIFAR-10.
        \item Week 5--6: Experiment with incremental improvements and alternative optimizers.
        \item Week 7--8: Final evaluation and report preparation.
    \end{itemize}


    \section{Conclusion}\label{sec:conclusion}
    Through this proposal, we aim to develop a differentially private deep learning model that achieves strong
    privacy guarantees while enhancing the performance of existing techniques.
    We will use DP-SGD as a baseline and investigate adaptations to DP-Adam and DP-RMSprop.
    Our focus will be on incremental improvements, including the integration of automatic clipping and possibly
    modifications to the noise mechanism, to achieve competitive accuracy on CIFAR-10 while ensuring
    robust privacy protection.


    \bibliographystyle{plainnat}
    \bibliography{references}


    \section*{GitHub link sharing?}


\end{document}
