\subsection{Current Implementation Overview}\label{subsec:current-implementation}

\begin{table}[!ht]
    \caption{Experimental Results\\
    All experiments were conducted with a privacy budget $\delta = 10^{-5}$. Momentum, Weight Decay, and Max Gradient Norm are all constant in these tests.}
    \centering  % Center the table
    \resizebox{\textwidth}{!}{  % Resize the table to fit the width of the page
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
            \hline

            \textbf{Experiment ID} & \textbf{Optimizer} & \textbf{Epochs} & \textbf{Accuracy} & \textbf{Training Time (s)} & \textbf{Privacy Cost} & \textbf{Learning Rate} & \textbf{Batch Size} & \textbf{Noise Multiplier} \\ [0.5ex]
            \hline\hline
            1                      & SGD                & 100             & 87\%              & -                          & -                     & 0.1                    & 128                 & -                         \\
            2                      & SGD                & 200             & 94\%              & -                          & -                     & 0.1                    & 128                 & -                         \\
            \textbf{3}             & \textbf{DP-SGD}    & \textbf{30}     & \textbf{41\%}     & \textbf{481.49}            & \textbf{3}            & \textbf{0.1}           & \textbf{128}        & \textbf{1.1}              \\
            4                      & DP-SGD             & 30              & 40\%              & 598.68                     & 3                     & 0.2                    & 128                 & 1.1                       \\
            5                      & DP-SGD             & 30              & 39\%              & 527.37                     & 3                     & 0.3                    & 128                 & 1.1                       \\
            6                      & DP-SGD             & 30              & 37\%              & 584.55                     & 3                     & 0.4                    & 128                 & 1.1                       \\
            7                      & DP-SGD             & 30              & 38\%              & 597.60                     & 3                     & 0.5                    & 128                 & 1.1                       \\
            8                      & DP-SGD             & 30              & 35\%              & 995.68                     & 3                     & 0.1                    & 64                  & 1.1                       \\
            \textbf{9}             & \textbf{DP-SGD}    & \textbf{30}     & \textbf{44\%}     & \textbf{473.86}            & \textbf{3}            & \textbf{0.1}           & \textbf{256}        & \textbf{1.1}              \\
            10                     & DP-SGD             & 30              & 44\%              & 597.29                     & 2.99                  & 0.1                    & 512                 & 1.1                       \\
            11                     & DP-SGD             & 30              & 42\%              & 677.04                     & 3                     & 0.1                    & 1024                & 1.1                       \\
            12                     & DP-SGD             & 30              & 43\%              & 519.55                     & 8.01                  & 0.1                    & 128                 & 1.1                       \\
            13                     & DP-SGD             & 30              & 44\%              & 627.49                     & 10.01                 & 0.1                    & 128                 & 1.1                       \\
            14                     & DP-SGD             & 30              & 48\%              & 553.12                     & 50.04                 & 0.1                    & 128                 & 0.1                       \\
            \textbf{15}            & \textbf{DP-SGD}    & \textbf{30}     & \textbf{50\%}     & \textbf{375.37}            & \textbf{50.04}        & \textbf{0.1}           & \textbf{256}        & \textbf{0.1}              \\

            \hline
        \end{tabular}
    } % End of \resizebox
    \label{tab:exp_results}  % Label of the table
\end{table}

\subsection{Best Observed Accuracy and Components/Hyperparameters}\label{subsec:best-accuracy}
In the Experimental testing above, we varied various hyperparameters to maximize accuracy of classification on the CIFAR10 dataset. We employed the
(Epsilon, Delta)-Differentially Private - Stochastic Gradient Descent (DP-SGD) as our optimizer. For our loss function, we used the built-in PyTorch CrossEntropy function.
The bolded lines indicate the maximum accuracies achieved for each of the hyperparameters that we explored.
\begin{itemize}
    \item \textbf{Learning Rate:} We varied learning rate from 0.1 to 0.5. The smallest learning rate (0.1) yielded the highest accuracy of 41\%.
    \item \textbf{Batch Size:} We varied batch size from 64 to 1024. A batch size of 256 yielded the highest accuracy of 44\% among its peers.
    \item \textbf{Epsilon/Privacy Bugdet:} Higher epsilons mean lower privacy, but also can mean higher utility. When the epsilon was adjusted to 50, accuracy peaked at 50\%.
    \item \textbf{Noise Multiplier:} Along with Epsilon changes, our highest accuracy (50\%) run also coincided with a decrease in noise multiplier (0.1).
\end{itemize}

\subsection{Failed Approaches}\label{subsec:failed-approaches}

\subsection{Training Methods}\label{subsec:training-methods}

