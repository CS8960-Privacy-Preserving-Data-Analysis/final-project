\documentclass{article}

\usepackage[preprint]{neurips_2024}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}

\title{Differential Privacy in Image Classification using ResNet-20 and DP-SGD Optimization}

\author{
  Praveen Rangavajhula\\
  Department of Computer Science\\
  University of Georgia\\
  Athens, GA, 30602\\
  \texttt{praveen.rangavajhula@uga.edu} \\
  \And
  Alexander Darwiche\\
  Department of Computer Science\\
  University of Georgia\\
  Athens, GA, 30605 \\
  \texttt{alexander.darwiche@uga.edu} \\
  \And
  Team Member 2 \\
  Department of Computer Science\\
  University of XYZ\\
  City, State, ZIP Code \\
  \texttt{team.member2@xyz.edu} \\
}

\begin{document}

\maketitle

\begin{abstract}
  This project proposes a differentially private image classification system using ResNet-20 and Differentially Private Stochastic Gradient Descent (DP-SGD). We explore both non-private optimizers and DP versions, justifying the choices based on prior work and their potential to outperform others. The project will focus on achieving competitive accuracy while satisfying privacy guarantees.
\end{abstract}

\section{Introduction}
The proliferation of machine learning models, especially in image classification, has raised concerns over privacy. Differential privacy (DP) is a framework that helps ensure models do not inadvertently leak sensitive information about individuals in the underlying training data. We propose using ResNet-20, a convolutional neural network (CNN) model, to classify images from the CIFAR-10 dataset. Also, we propose the implementation and improvement of DP-SGD, an existing algorithm for training deep learning models, while adhering to the Differential Privacy Framework.

\section{Motivation and Problem Statement}
In many real-world applications, such as healthcare and finance, privacy concerns hinder the deployment of machine learning models. Current state-of-the-art models like ResNet-20 achieve high accuracy but are vulnerable to attacks that could leak sensitive information. By incorporating differential privacy through the use of an improved DP-SGD, we aim to develop a model that balances both accuracy and privacy.

\section{Methodology}
\subsection{Model Architecture: ResNet-20}
We will implement the ResNet-20 model for CIFAR-10, a standard dataset for image classification tasks.

\subsection{Non-private Optimizers to Try}
We will first experiment with non-private optimizers to establish baseline performance for ResNet-20 on CIFAR-10. The following optimizers will be explored:
\begin{itemize}
    \item \textbf{SGD:} Standard Stochastic Gradient Descent for baseline comparison.
    \item \textbf{Adam:} Adaptive Moment Estimation for better convergence in non-private settings.
    \item \textbf{RMSprop:} To explore gradient normalization impact in non-private training.
\end{itemize}

\subsection{Differentially Private Optimizer: DP-SGD}
We will implement DP-SGD as our privacy-preserving algorithm. The key components of DP-SGD are:
\begin{itemize}
    \item \textbf{Gradient Clipping:} Limits the influence of individual examples during training.
    \item \textbf{Noise Addition:} Adds noise to gradients to ensure privacy (via Opacus or TensorFlow Privacy libraries).
    \item \textbf{Privacy Accounting:} We will use Rényi Differential Privacy (RDP) for privacy budget tracking.
\end{itemize}

\subsection{Incremental Improvements}
We plan to explore the following enhancements:
\begin{itemize}
    \item Alternative noise mechanisms and their effect on utility-privacy tradeoffs.
    \item Adaptive gradient clipping methods that dynamically adjust the clipping threshold.
    \item Experimenting with different optimizers (e.g., DP-Adam).
\end{itemize}

\subsection{Rationale for Choosing DP-SGD}
\begin{itemize}
    \item DP-SGD provides well-documented privacy guarantees (Abadi et al. 2016) while maintaining decent utility for image classification tasks.
    \item The addition of noise and gradient clipping help ensure $(\epsilon, \delta)$-differential privacy, making it ideal for sensitive applications.
    \item Previous work shows that DP-SGD, when optimized, can yield near state-of-the-art accuracy for differentially private models (De et al. 2022).
\end{itemize}

\subsection{Why This Approach Will Outperform Others}
\begin{itemize}
    \item Our approach leverages the simplicity of ResNet-20, optimized for smaller datasets like CIFAR-10, combined with DP-SGD, a proven differential privacy technique.
    \item By experimenting with different gradient clipping techniques and noise scales, we aim to find an optimal trade-off between accuracy and privacy.
    \item We will investigate modifications like adaptive clipping to enhance performance.
\end{itemize}

\subsection{Pseudo-code for Non-Private SGD}
Below is a simplified pseudo-code for the non-private SGD we plan to privatize:
\begin{verbatim}
for each batch (X, y):
    pred = model(X)
    loss = loss_fn(pred, y)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
\end{verbatim}

\section{Experimental Setup}
\subsection{System Description}
We will use PyTorch for model implementation and training. The DP-SGD implementation will be based on the Opacus library. Training will be performed on GPUs available via our departmental server.

\subsection{Dataset}
We will use the CIFAR-10 dataset, consisting of 60,000 32x32 RGB images, which is commonly used for image classification tasks. The dataset is built-in in PyTorch, and we will load it using standard libraries.

\subsection{Metrics}
\begin{itemize}
    \item \textbf{Training Loss/Accuracy:} Standard accuracy on CIFAR-10 for both non-private and private models.
    \item \textbf{Privacy Budget:} We will measure $(\epsilon, \delta)$ using RDP to ensure privacy compliance.
    \item \textbf{Efficiency:} Time complexity and memory usage will be tracked.
\end{itemize}

\subsection{Baseline Models}
We will compare the performance of DP-SGD with non-private models and other private optimizers like DiceSGD. 

\section{Related Work}
Several approaches to differentially private deep learning have been explored in the literature. \citet{abadi2016deep} introduced DP-SGD, which remains the most widely used technique for privacy-preserving model training. Recent works like \citet{de2022unlocking} have explored scaling DP training for improved accuracy, which is also one of our goals.

\section{Timeline and Milestones}
\begin{itemize}
    \item Week 1-2: Implement ResNet-20 for CIFAR-10.
    \item Week 3-4: Integrate DP-SGD using the Opacus library and test on CIFAR-10.
    \item Week 5-6: Experiment with incremental improvements and alternative optimizers.
    \item Week 7-8: Final evaluation and report preparation.
\end{itemize}

\section{Conclusion}
Through this proposal, we aim to develop a differentially private deep learning model that can achieve state-of-the-art accuracy on CIFAR-10 while providing strong privacy guarantees. We will explore DP-SGD as a baseline and investigate potential improvements in both privacy and efficiency.

\section*{References}
\small{
[1] Abadi, M., Chu, A., Goodfellow, I., McMahan, H. B., Mironov, I., Talwar, K., \& Zhang, L. (2016). Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (pp. 308–318).

[2] De, S., Berrada, L., Hayes, J., Smith, S. L., \& Balle, B. (2022). Unlocking high-accuracy differentially private image classification through scale. arXiv preprint arXiv:2204.13650.
}

\section*{GitHub link sharing?}


\end{document}
